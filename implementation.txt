####################
2021.11.12

Tried training together different inputs with same sample size
Looks quite ok

Extremely small dataset for ProgramCommittee, Conference, ProgramCommitteeMember, siteURL, title, date: works rather bad

####################
2021.11.11

cmt_renamed is mostly aligned

problems where there are very few datapoints
ProgramCommitteeChair: the same fact has many proofs with the same prefix but different (existential) variable in the body, making the prefix much more probable than it should

Conferences
ProgramCommittee

Filter results with a rule parser
train together
- synthetic
- real data

How to balance datapoints of different size when training together?

date mapping failed completely. Why?
label mapping failed completely. Why?
siteURL mapping failed completely. Why?


####################
2021.10.19

The mapping problem can be seen as a translation task (sequence to sequence)

Input: ground head of a rule
Output: ground body of a rule

Ex:
{C,a,stop} -> {R1,a,b,and,R2,b,23,stop}

"stop" indicates end of intput/output
"and" indicates that a new predicate is coming

1. Take a bunch of rule templates
2. For each template and each supervision fact, generate a lot of ground (head, body) pairs
3. Train a transformer to predict body from head
3. For evaluation sample a fixed K number of bodies
   A positive supervision fact passes the test if some body is true in the source
   A negative supervision fact passes the test if none of the sampled bodies are true in the source
4. Potentially extract rules by lifting generated ground rules

There will be a tradeoff between positive and negative successes based on K
   Large K makes it easier for a positive to pass
   Smaller K makes it easier for a negative to pass
An ROC curve can show this well
   plot true positive rate (true positives / positives) against false positive rate (false positive / negatives)


Input: list of tokens
Output: list of tokens
Embed them to integers, so we get list of integers

####################
2021.10.14

collect positive and negative samples for each auxiliary symbol Apred

positive sample: Apred -> (Spred1,...Spredk) in mapping of positive fact
negative sample: Apred -> (Spred.....      ) in mapping of negative fact

take a positive-negative pair
     push away from all negatives
     push towards closest closest remaining positive


####################
2021.10.06


What if we don't embed constants
Only embed predicates

Loss is just the distance between the target and auxiliary
predicates that appear in the mapping are pushed towards
each other


####################
2021.10.05

pseudocode for training

for F in {facts in the supervision}:
    for R in {rules matching F}:
        Rloss_vect = []
    	for B in {bodies associated with R}:
    	    Loss(B) = 0
    	    for A in {atoms in B}:
    	    	Loss(A) = {some differentiable formula of our parameters}
	    	Loss(B) += Loss(A)
    	    RLoss_vect.append(Loss(B))
    	Loss(R) = sum(RLoss_vect * softmin(RLoss_vect))
	# softmin is over a large set
    Loss(F) = min {Loss(R) | R in rules matching F}
    # min is over a small set

create a tf/pt model for each fact in the supervision
the model refers to embedding vectors (identified by name)

one extra model for plain embedding of source db preds/constants

####################
2021.10.01

RODI synthetic datasets contain around 5K constants
RODI Norwegian contains around 200K constants
Embed the database using TransH

For each supervision and each fitting rule, collect candidate proofs in the form of
- mapping of body predicates
- variable instantiations





####################
2021.10.01

Embed:
C(a): emb(C) = emb(a)
R(a,b): emb(a) + emb(R) = emb(b)

Example

Author(a):- Person_id_type(a,1)
Author(a):- Author_id(a)

Author(X):- A1(X,Y).
Author(X):- A2(X).

A2 objective
   emb(A2) = emb(Author_id)
   emb(A2) = =emb(a)

A1 objective
   emb(A1) = emb(Person_id_type)
   emb(a) + emb(A1) = emb(1)

####################
2021.09.30

Suppose the source consists of
- unary facts S(a), derived from some column in some table
- binary facts R(a,b) derived seom some pair of columns in some table

Suppose we have an embedding of all
- source predicates (unary, binary)
- auxiliary predicates
- source/target constants

Suppose that source/target constants are the same

Suppose that the body contains on variables that are not connected to
any constant or head variable via some relational chain. So we
disallow rules like
H(X):- A(X), B(Y).

We collect candidate proofs for a supervision fact using exact
matching on the constants and fuzzy matching on the predicates.


# BodyList: atom from the body of a rule
# Subst: key-value pairs mapping some variables in the body to constants
#        Subst(B) is shorthand for applying Subst to B
# Mapping: key-value pairs mapping some auxiliary body predicates to source predicates
# we assume a fuction embeddingScore: Mapping -> [0,1]
# return: list of mappings of auxiliary predicates to source predicates that yield a solution to the supervision
def candidate_mappings(Body, Subst, Mapping):

   if len(Body) == 0:
      return [Mapping]
    
   select B in Body, such that #variables is minimal in Subst(B)
   Body2 is Body \ {B}

   Facts is all facts from the source can be soft unified with Subs(B)
   # have the same arity as B and has the same constant in the same position
   # since Subst(B) contains some constants, Facts is much smaller than the dataset

   result = []
   for F in Fact:
       Subs2 is Subst + mgu(Subst(B), F)
       Mapping2 is Mapping + {pred(B) -> pred(F)}
       score = embeddingScore(Mapping2)
       # if there are too many candidate facts in Facts, sample from them based on score
       # for negative samples, it is ok to use a threshold for score
       # for positive samples, farther candidates should have a chance too

       new_mappings = candidate_mappings(Body2, Subst2, Mapping2)
       result += new_mappings

   return result

for each s in P union N:
    target_s = 1 if s in P else 0
    for each rule H:-Body with fitting head:
    	Subst0 is mgu(p,H)
	mappings = candidate_mappings(Body, Subst0, [])
	scores = [embeddingScore(m) for m in Mappings]
	score = sum(scores * softmax(scores))
	loss = (target_s - score)^2
	update embedding to reduce loss


####################
2021.09.30

Ontology:
- Classes: person

Database:
- t_person(pid, cid)

Suppose that we have the following mapping rule:
person(X):- t_person.A(X).

where A is an auxiliary predicate to be matched with one of the columns of t_person.

Unifying A with pid, cid gives scores s1, s2.

person(a) how has two potential proofs
	  T_person.pid(a) or T_person.cid(a)

If one proof is better for some a_i and the other is better for some other a_j, then it make sense to learn which one we select eventually.

####################
2021.09.29

Ontology:
- Classes: person, company
- Predicates: name(company union person -> string), worksFor(person -> company), isLeadBy (company -> person)

Database:
- t_person(pid, cid, pname, junk)
- t_company(cid, pid, cname, junk)

Suppose that we have the following mapping rules:
c(X):- T.A(X).
r(X,Y):- T.A1(X), T.A2(Y).

Naively
- person can be assigned to 8 table-attribute pairs.
- company can be assigned to 4 attributes in the other table.
- name can be assigned to 3 different attibutes for each class, giving 3 * 3 = 9 options
- worksFor can be assigned to any of the remaining 4 attributes (in either table)
- isLeadBy can be assigned to any of the remaining 3 attributes (in either table)

This is 8*4*9*4*3 = 3456 possible mappings.
We can eliminate many mappings based on type information.

If we have any supervision on person/company, we can quickly eliminate all but two candidate columns for each: persons live in the pid columns, companies live in the cid columns
If we have any supervision on worksFor/isLeadBy, we can quickly eliminate a lot of mappings purely based on what column pairs contain  the supervision pairs
If we have supervision with more then pairs, we can eliminate more mappings, again based on what constants individual columns hold.

Suppose that after all this elimination, some of the mappings are known:
person(X):- t_person.pid(X).
company(X):- t_company.cid(X).
name(X:person, Y):- t_person.pid(X), t_person.pname(Y).
name(X:company, Y):- t_company.cid(X), t_company.cname(Y).
worksFor(X, Y):- t_person.pid(X), t_person.cid(Y).

So we only need to figure out where isLeadBy reside. There are four candidates:
isLeadBy(X, Y):- t_person.pid(Y), t_person.cid(X).
isLeadBy(X, Y):- t_person.pid(Y), t_person.junk(X).
isLeadBy(X, Y):- t_company.cid(X), t_company.pid(Y). # correct one
isLeadBy(X, Y):- t_company.cid(X), t_company.junk(Y).

Our mapping rule is like the aboves, but the body contains auxiliary predicates:
isLeadBy(X, Y):- T.A1(X), T.A2(Y).
Matching the candidates with our mapping rule gives scores s1, s2, s3, s4.
We evaluate the database according to the four candidates and calculate an aggregate score for all of our supervision.
The best coverage is provided by candidate#3, so a gradient step would move towards T->t_company, A1->cid, A2->pid,
making s3 higher in the next round (and possibly but not necessarily making s1, s2, s4 smaller).

This is the learning algorithm we had in mind. However, as soon as candidate#3 performs best, we can just stop and say that this is going to be our mapping.
Why would we bother with learning?

####################
2021.09.29

Note about the formalism:
When I say below that
T.A1(Y) where T_A2=X
this is not a proper logical expression, but an sql query. It should be read as

T'(C_1, C_2, â€¦C_k), C_{I(A1)}=Y, C_{I(A2)}=X
where I is a mapping from column names in table T to their position in relation T'

*********************


problem_set: npd_user_tests
query: query1.qpair

*********************
name=Who are the licensees of production licence X and how big is their share?
orderNum=1

sql=SELECT DISTINCT a.prlName, a.cmpLongName, a.prlLicenseeInterest, a.prlLicenseeDateValidTo FROM licence_licensee_hst a WHERE a.prlLicenseeDateValidTo IN (SELECT MAX(b.prlLicenseeDateValidTo) FROM licence_licensee_hst b WHERE a.prlName = b.prlName GROUP BY b.prlName) ORDER BY a.prlName

sparql=prefix npdv: <http://sws.ifi.uio.no/vocab/npd-v2> \n\
SELECT DISTINCT ?licence ?licensee ?interest ?date WHERE { ?licenceURI a npdv:ProductionLicence ; npdv:name ?licence . [ ] a npdv:ProductionLicenceLicensee ; npdv:dateLicenseeValidFrom ?date ; npdv:licenseeInterest ?interest ; npdv:licenceLicensee [ npdv:name ?licensee ] ; npdv:licenseeForLicence ?licenceURI . { SELECT ?licenceURI (MAX(?d) AS ?date) WHERE { [ ] a npdv:ProductionLicenceLicensee ; npdv:dateLicenseeValidFrom ?d ; npdv:licenseeForLicence ?licenceURI . } GROUP BY ?licenceURI } } ORDER BY ?licence DESC(?interest)

entityIdCols=
entityIdVars=
*********************

mapping rules:

npdv:ProductionLicence(X):-
  source conditions: license_licensee_hst.prlnpdidlicence(X)

npdv:ProductionLicenceLicensee(X):-
  source conditions: license_licensee_hst.cmpnpdidcompany(X)

npdv:name(X, Y):-
  target conditions: rdf:type(X, npdv:ProductionLicence)
  source conditions: license_licensee_hst.prlName(Y) where license_licensee_hst.prlnpdidlicence = X

npdv:dateLicenseeValidFrom(X,Y):-
  target conditions: rdf:type(X, npdv:ProductionLicenceLicensee)
  source conditions: license_licensee_hst.prlLicenseeDateValidTo(Y) where license_licensee_hst.cmpnpdidcompany = X
  # note there is probably a bug in the provided sql as it uses DateValidTo instead of DateValidFrom

npdv:licenseeInterest(X, Y):-
  target conditions: rdf:type(X, npdv:ProductionLicenceLicensee)
  source_conditions: license_licensee_hst.prlLicenseeInterest(Y) where license_licensee_hst.cmpnpdidcompany = X

npdv:licenceLicensee(X,Y):-
  target conditions: rdf:type(X, npdv:ProductionLicenceLicensee)
  source conditions: license_licensee_hst.cmpLongName(Y) where license_licensee_hst.cmpnpdidcompany = X
  # note this is an approximation. Y is in fact an entity (company) whose :name property is license_licensee_hst.cmpLongName


####################

Use the RODI benchmark

Supervision:
SQL query tells us what we want to obtain when we run the sparql query

x rdf:type C:
  Q.id gives you all x

  Q1.id gives you all x, but other relations are in Q2
  Q1 natural join Q2

x y z:
  x and z should have corresponding rdf:type edges and they come from
  the id column of the corresponding tables
  call them table(x) and table(z)

  if y is a functional property, then it should correspond to a column col
  in table(x), i.e., (x,z) pairs are
  (table(x).id, table(x).col)

  if y is an inverse functional property, then it should correspond to a column col
  in table(z), i.e., (x,z) pairs are
  (table(z).col, table(z).id)

  if y is not a functional property, then look for a table
  corresponding to y and identify the column corresponding to z

  if y is not a functional property, then look for a table
  corresponding to z and identify the inverse column corresponding to
  x


  create an fixed embedding vector for each sql table
  create a trainable embedding vector for each owl:Class
  these have to be matched during training

  create a fixed embedding vector for each column name in each sql
  table
  create a trainable embedding vector for each
  owl:FunctionalProperty
  these have to be matched
  TODO: assume that the same column name is not used in different
  tables to mean different things

  same as above for owl:InverseFunctionalProperty


  for each functional property
  create a fixed embedding vector for each column of each table

  for each functional property, create an embedding vector

  create a trainable embedding vector  for


Bind each class C_i to a table T_i
Bind each functional property to
     - column in class table of subject T_s.p
Bind each inverse functional property to
     - column in class table of object T_o.p
Bind each plain property to a table T_prop_i

SELECT count(*)
FROM T_i, T_prop_j
WHERE T_i.id = T_prop_j.xxx


generate problems automatically (sparql, sql, triples, selects)
try brute force mapping search

automatically compare sql and transformed sql results


One query from npd
atomic-ZValueTo.qpair
sparql=SELECT ?x ?y { ?x <http://sws.ifi.uio.no/vocab/npd-v2#ZValueTo> ?y }

Solution is the union of two tables (tables and subject columns are specified in comments in the ontology)

Object is harder as it is split in multiple columns

'http://sws.ifi.uio.no/data/npd-v2/licence/' + TABLE1.prlNpdidLicence +
'/area/' + TABLE1.prlArea_id +
'/history/', TABLE1.prlAreaPolyDateValidFrom +
'/', TABLE1.prlAreaPolyDateValidTo

union

'http://sws.ifi.uio.no/data/npd-v2/licence/' + TABLE1.prlNpdidLicence +
'/block/' + TABLE1.blcName +
'/polyno/' + TABLE1.prlAreaPolyPolyNo +
'/history/' + TABLE1.prlAreaPolyDateValidFrom +
'/' + TABLE1.prlAreaPolyDateValidTo


C(x):- 
