\documentclass{easychair}
% \documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{xspace}
\usepackage[parfill]{parskip}
\usepackage[title]{appendix}
\usepackage{paralist}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}

\newcommand{\p}{proj}
\newcommand{\body}{body}
\newcommand{\atom}{atom}
% \newcommand{\rule}{rule}

\title{Learning Based Relational-to-Ontology Mapping}

\begin{document}

\author{
  author\inst{1}
}

\institute{
  institute, Oxford
}


\maketitle

\section{Problem statement}

Given a source schema $\mathbb{S}$ that consists of source predicates $S_1 \dots S_k$.

Given an instance $I_{\mathbb{S}}$ that contains source facts.

Given a target schema $\mathbb{T}$ that consists of target predicates
$T_1 \dots T_l$. This corresponds to some RDF ontology. 

We assume that a domain expert has provided us with a set $\mathbb{MT}$
of mapping templates. A mapping template can be seen as a set of
mapping rules.  The head of a mapping rule is a target atom and the
body is some logical formula that can contain auxiliary predicates and
auxiliary constants. Matching the auxiliary predicates and constants
with source predicates and constants yields a mapping rule that is an
instance of the template. Mapping rules are typically conjunctive queries.

We assume that for each target predicate $T \in \mathbb{T}$ we are
provided with a set $\mathbb{P}$ of positive facts $T(args)$ and a set
$\mathbb{N}$ of negative facts $T(args)$.

Our task is to find a subset $\mathbb{M}$ of the instantiations of the mapping
templates $\mathbb{MT}$ such that the source database instance $I_{\mathbb{S}}$ and the mapping
rules $\mathbb{M}$ together imply all the positive facts $\mathbb{P}$ and none
of the negative facts $\mathbb{N}$. We are also interested in the
relaxation of this problem, when we want to cover ``as many as
possible'' of the positive facts and ``as few as possible'' of the
negative facts.

\section{Candidate mapping rules}
For any positive or negative fact $F$ and mapping template $MT \in
\mathbb{MT}$, we define the \emph{candidates} of $F$ with respect to
$MT$ to be the set of all instantiations $M$ of $MT$ such that $M$,
together with the source instance implies $F$:

$$\mbox{candidates}(F, MT) = \{M | M \in MT, (M \land I_{\mathbb{S}} \vDash F)\}$$ 

It is straightforward to extend the definition of candidates to sets of mapping templates:

$$\mbox{candidates}(F, \mathbb{MT}) = \bigcup_{MT \in \mathbb{MT}} \mbox{candidates}(F, MT)$$

We extend candidates to sets of facts using multiset union:

$$\mbox{candidates}(\mathbb{P}, \mathbb{MT}) = \biguplus_{F \in \mathbb{P}} \mbox{candidates}(F, \mathbb{MT})$$
$$\mbox{candidates}(\mathbb{N}, \mathbb{MT}) = \biguplus_{F \in \mathbb{N}} \mbox{candidates}(F, \mathbb{MT})$$

The multiplicity of a rule tells us how many of the target supervision
facts the rule can prove.

When it is clear from context, we will sometimes omit reference to
$\mathbb{MT}$ and use $\mbox{candidates}(F)$,
$\mbox{candidates}(\mathbb{P})$ to refer to the set of candidates of a
single fact or the multiset of candidates of a fact set.

We can associate with each mapping rule the set of facts that it proves:

$$\mbox{consequences}(M, \mathbb{P}) = \{F | F \in \mathbb{P}, M \in \mbox{candidates}(F, \mathbb{MT}) \}$$
$$\mbox{consequences}(M, \mathbb{N}) = \{F | F \in \mathbb{N}, M \in \mbox{candidates}(F, \mathbb{MT}) \}$$

\section{Problem reformulated}

\subsection{Maximum coverage problem}

If we disregard the negative supervision and focus on finding the best
$k$ rules for the positive facts, then we obtain an instance of the
NP-hard maximum coverage problem, where the sets to select from are
$\{\mbox{consequences}(M, \mathbb{P}) | MT \in \mathbb{MT}, M \in MT
\}$ and the set to be covered is $\mathbb{P}$.

If the negative supervision is treated as hard constraint, then we can
eliminate all rules whose consequence set in the negative supervision is
nonempty and solve the maximum coverage problem for the remaining
sets.

\subsection{Alignment via function approximation}

An alternative to the maximum coverage problem is to consider the
function that takes a fact and yields a corresponding mapping rule and
try to approximate this based on the data we have. Here is some
motivation for this approach:

\begin{itemize}
\item Solving the maximum coverage problem might be too expensive.
\item There may be no perfect solution (that avoids all negatives and proves all positives)
\item We may have errors in the database or in the supervision.
\item We want the system to generalise to unseen facts.
\end{itemize}

Let us define stochastic rule generator function $G:\mbox{fact}
\rightarrow \mbox{rule}$ which takes a fact in the target language and
outputs a mapping rule that proves the given fact. $G$ essentially
represents the relationship between atom $F$ and
$\mbox{candidates}(F)$.

For each positive fact $P$ $\mbox{candidates}(P)$ is the set of rules
that are equally good for proving $P$. So there is a do not care
nondeterminism when we select from the candidates, as far as $P$ is
concerned. The restriction imposed by fact $P$ on $G$ is that all the
probability mass for input $P$ lie in $\mbox{candidates}(P)$, i.e.,

$$\forall P \in \mathbb{P}: \left(\sum_{M \in \mbox{candidates}(P)} prob(G(P) = M)\right) = 1$$

The situation is different for a negative fact $N$, since we expect
the generator to assign zero probability to the candidates of $N$ for
any positive input $P$:

$$\forall N \in \mathbb{N}: \forall P \in \mathbb{P}: \left(\sum_{M \in \mbox{candidates}(N)} prob(G(P) = M)\right) = 0$$

We select $G$ from a parametric set of functions and aim to learn the
parameters with stochastic gradient descent based on the supervision
facts and their candidate rules. We introduce a loss function $L$ that
quantifies how much the above constraints are violated and we minimise the loss function.


\begin{align*}
L(P) & = 1 - \left(\sum_{M \in \mbox{candidates}(P)} prob(G(P) = M)\right) \\
L(N) & = \sum_{P \in \mathbb{P}} \left(\sum_{M \in \mbox{candidates}(N)} prob(G(P) = M)\right) \\
L & = \sum_{P \in \mathbb{P}} L(P) + \sum_{N \in \mathbb{N}} L(N)
\end{align*}

\section{Learning the generator with a transformer language model}

We consider some textual representation of both facts (inputs of $G$)
and mapping rules (outputs of $G$), so we train a sequence-to-sequence
model. In this model family, transformers represent the state of the
art.

A transformer first embeds the input sequence and then generates
tokens sequentially, so that the next token is conditioned on the
input embedding and all previously generated output tokens. In each
step, the model output is a probability distribution over all
tokens. We can sample from this distribution or take the one with
maximal probability. Generation stops when a special ``End Of
Sequence'' token is generated.  The probability of the entire
generated sequence is the product of the probabilities of the
individual tokens.

For positive fact $P$, all the rules in $\mbox{candidates}(P)$ should
be evaluated together, since we are constraining the sum of their
probabilities, not the individual probabilities of rules.

So, within one epoch of learning, loop through all P, N pairs:
\begin{itemize}
\item Take $G(P)$ and evaluate the probabilities assigned to each rule in $\mbox{candidates}(P)$ and $\mbox{candidates}(N)$
\item Compute losses, as defined above
\item Perform a gradient step
\end{itemize}


%% \section{TODO}

%% Theory on the target.

%% No exact matching between source and auxiliary predicates/constants

%% Higher arity relations in the target.

%% \section{Terminology}

%% Let us suppose that we only have unary and binary relations. The
%% source database contains facts of the form

%% \begin{align}
%%   C(a) \\
%%   R(a, b)
%% \end{align}

%% We have a set of positive facts


%% \section{Training}

%% \begin{itemize}
%% \item $\mathcal{L}(C_s(a)) = ||\p(\vec{a},C_s) - \vec{C_s}||_2$.
%% \item $\mathcal{L}(R_s(a,b)) = ||\p(\vec{a},R_s) + \vec{R_s} - \p(\vec{b},R_s)||_2$.
%% \item $\mathcal{L}([C_a(a), C_s]) = ||\p(\vec{a},C_a) - \vec{C_a}||_2 + ||\vec{C_a} - \vec{C_s}||_2$.
%% \item $\mathcal{L}([R_a(a,b), R_s]) = ||\p(\vec{a},R_a) + \vec{R_a} - \p(\vec{b},R_a)||_2 + ||\vec{R_a} - \vec{R_s}||_2$.
%% \item $\mathcal{L}(\body) = \sum_{(\atom_a, R_s) \in \body} \mathcal{L}(\atom_a, R_s)$
%% % \item $\mathcal{L}(\rule) = \sum_{(\atom_a, R_s) \in \body} \mathcal{L}(\atom_a, R_s)$
%% \item

%% \end{itemize}





\end{document}
